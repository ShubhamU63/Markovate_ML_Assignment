 ```
Experimentation, Reproducibility & Deployment Pipeline/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                     # FastAPI app entry point
â”‚
â”‚
â”œâ”€â”€ Data_Ingestion/
â”‚   â”œâ”€â”€ data_ingestion.py           # Data validation, logging, YAML loading
â”‚   â”œâ”€â”€ __init__.py
â”‚ 
â”œâ”€â”€ Model_Training/
â”‚   â”œâ”€â”€ train.py                    # Model training pipeline
â”‚
â”œâ”€â”€ Model_Artifacts_Registry/
â”‚   â”œâ”€â”€ models/                     # Saved model pipelines
â”‚   â””â”€â”€ reports/                    # Generated classification reports
â”‚
â”œâ”€â”€ Baseline/train.csv              # Baseline dataset schema reference
â”œâ”€â”€ config/params.yaml              # Model parameters & training configs
â”œâ”€â”€ Monitoring/                     # Logs (validation, errors, training)
â”‚   â”œâ”€â”€ error.log                     # Saved model pipelines
â”‚   â””â”€â”€ training.log
â”‚   â””â”€â”€ validation.log
â”œâ”€â”€ sapp.py                      # Streamlit frontend app
â”‚
â”‚
â”œâ”€â”€ requirement.txt
â””â”€â”€ README.md
 ```
![alt text](<Mlops Architecture.png>)

## Clone Repository

git clone [<your-repo-url>](https://github.com/ShubhamU63/Markovate_ML_Assignment.git)
cd project_root

## Create Virtual Environment
python -m venv venv
source venv/bin/activate   # for Linux/Mac
venv\Scripts\activate   

## Install Dependencies
pip install -r requirements.txt

## Backend â€“ FastAPI---Run FastAPI
uvicorn app.main:app --reload

Server runs at ðŸ‘‰ http://127.0.0.1:8000

## Frontend â€“ Streamlit --Run Streamlit
streamlit run frontend/app.py


Frontend runs at ðŸ‘‰ http://localhost:8501



## Example Response

```
{
  "message": "Model trained successfully",
  "accuracy": 0.83,
  "model_path": "Model_Artifacts_Registry/models/pipeline_model_20251029_202100.joblib",
  "report_path": "Model_Artifacts_Registry/reports/report_20251029_202100.txt"
}
```

## Streamlit Frontend Features
File uploader for dataset CSV

Sends data to /train-model endpoint

Displays training metrics in a styled box

Shows report text file output directly in the interface


## Configuration (config/params.yaml)


seed: 42
test_size: 0.2



## Logging
All logs are stored in the Monitoring/ directory:

validation.log â†’ Data validation steps

error.log â†’ Any validation or ingestion errors

training.log â†’ Model training details


## Outputs
After running /train-model, the following artifacts are created:

Trained Model: Model_Artifacts_Registry/models/pipeline_model_<timestamp>.joblib

Report File: Model_Artifacts_Registry/reports/report_<timestamp>.txt

Accuracy: Displayed in frontend